{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9742232-229e-4673-9911-3ab0ebf488b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import cv2\n",
    "import logging\n",
    "from torchvision import models, transforms\n",
    "from torchvision.ops import nms\n",
    "#from torchvision.models import  resnet50, ResNet50_Weights\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR #, draw_ocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a8aae-1412-42c2-9532-0861d075febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging level to suppress YOLOv5 messages\n",
    "logging.getLogger('ultralytics').setLevel(logging.WARNING)\n",
    "# Set logging level to suppress PaddleOCR debug messages\n",
    "logging.getLogger('ppocr').setLevel(logging.WARNING)\n",
    "\n",
    "# Initialize the PaddleOCR reader\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "# Load the ResNet model\n",
    "# https://pytorch.org/vision/stable/models.html\n",
    "model_cars = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model_cars.eval()\n",
    "\n",
    "# Load the YOLOv5 model for license plate detection\n",
    "# Reference: License plate detection using YOLOv8\n",
    "# https://github.com/Muhammad-Zeerak-Khan/Automatic-License-Plate-Recognition-using-YOLOv8/blob/main/README.md\n",
    "model_plates = YOLO('../models/YOLO_license_plate_detector.pt')\n",
    "model_plates.eval()\n",
    "\n",
    "# Image transformation for YOLOv5\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d01b87-e767-4363-8117-ccff131e0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect objects (cars)\n",
    "#def detect_objects_cars(image_path, iou_threshold=0.5):\n",
    "def detect_objects_cars(image_cv2, iou_threshold=0.5):\n",
    "    image_rgb = cv2.cvtColor(image_cv2, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(image_rgb)\n",
    "\n",
    "    #image = Image.open(image_path)\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        results = model_cars(image_tensor)\n",
    "\n",
    "    # Extract bounding boxes, confidence scores, and class labels\n",
    "    predictions = results[0]\n",
    "    boxes = predictions['boxes']\n",
    "    scores = predictions['scores']\n",
    "    labels = predictions['labels']\n",
    "\n",
    "    # Apply Non-Maximum Suppression (NMS)\n",
    "    keep = nms(boxes, scores, iou_threshold)\n",
    "    boxes = boxes[keep].cpu().numpy()\n",
    "    scores = scores[keep].cpu().numpy()\n",
    "    labels = labels[keep].cpu().numpy()\n",
    "    \n",
    "    #return prediction\n",
    "    return {\"boxes\": boxes, \"scores\": scores, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1710d4f2-c28f-414f-83ad-c498d40e1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect objects (license plates)\n",
    "def detect_objects_plates(roi, iou_threshold=0.5):\n",
    "    results = model_plates(roi)\n",
    "    predictions = results[0]  # Access the first element of the list\n",
    "\n",
    "    # Extract bounding boxes, confidence scores, and class labels\n",
    "    boxes = predictions.boxes.xyxy\n",
    "    scores = predictions.boxes.conf\n",
    "    labels = predictions.boxes.cls\n",
    "\n",
    "    # Apply Non-Maximum Suppression (NMS)\n",
    "    keep = nms(boxes, scores, iou_threshold)\n",
    "    boxes = boxes[keep].cpu().numpy()\n",
    "    scores = scores[keep].cpu().numpy()\n",
    "    labels = labels[keep].cpu().numpy()\n",
    "\n",
    "    return {\"boxes\": boxes, \"scores\": scores, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6ca7f-20fc-4081-9aeb-446c45b29363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for OCR (License Plate Text) using PaddleOCR\n",
    "def extract_text_from_image(roi):\n",
    "    # Convert the image to grayscale\n",
    "    #gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Perform OCR using PaddleOCR\n",
    "    #result = ocr.ocr(gray, cls=True)\n",
    "    result = ocr.ocr(roi, cls=True)\n",
    "    if result == [None]:\n",
    "        #return \"\", gray, 0\n",
    "        return \"\", 0\n",
    "    text = \" \".join([line[1][0] for line in result[0]])\n",
    "    confidence = min([line[1][1] for line in result[0]])\n",
    "    #return text, gray, confidence\n",
    "    return text, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c4e99-c5b2-4052-a96e-90cd676a5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process an image for detection and OCR\n",
    "def process_image(image, frame_num=0, output_path=\"\"):\n",
    "    print(f\"Processing image started\")\n",
    "\n",
    "    # Data structure to store car, plate, and text data\n",
    "    car_data = []\n",
    "\n",
    "    #results_cars = detect_objects_cars(image_path)\n",
    "    results_cars = detect_objects_cars(image)\n",
    "    boxes = results_cars['boxes']\n",
    "\n",
    "    #image = cv2.imread(image_path)\n",
    "    for car_index, box_car in enumerate(boxes):\n",
    "        c_x1, c_y1, c_x2, c_y2 = box_car.astype(int)\n",
    "\n",
    "        # Extract the region of interest (ROI) for the car\n",
    "        roi_car = image[c_y1:c_y2, c_x1:c_x2]            \n",
    "\n",
    "        # Check if the ROI has non-zero dimensions\n",
    "        if roi_car.shape[0] == 0 or roi_car.shape[1] == 0:\n",
    "            #print(f\"Skipping empty ROI for car: {box_car}\")\n",
    "            continue\n",
    "\n",
    "        #print(f\"Detected car box: {box_car}\")\n",
    "        #c_text = f\"Detected car box: {box_car}\"\n",
    "\n",
    "        results_plates = detect_objects_plates(roi_car)\n",
    "        boxes_plates = results_plates['boxes']\n",
    "        for plate_index, box_plate in enumerate(boxes_plates):\n",
    "            #print(f\"Detected plate box: {box_plate}\")\n",
    "            #p_text = f\"Detected license plate text: {box_plate}\"\n",
    "            bp_x1, bp_y1, bp_x2, bp_y2 = box_plate.astype(int)\n",
    "\n",
    "            # Adjust coordinates relative to the original image\n",
    "            p_x1, p_y1, p_x2, p_y2 = bp_x1 + c_x1, bp_y1 + c_y1, bp_x2 + c_x1, bp_y2 + c_y1\n",
    "\n",
    "            # Extract the region of interest (ROI) for the number plate\n",
    "            roi_plate = image[p_y1:p_y2, p_x1:p_x2]            \n",
    "\n",
    "            # Extract text from the ROI\n",
    "            #text, plate_image, confidence = extract_text_from_image(roi_plate)\n",
    "            text, confidence = extract_text_from_image(roi_plate)\n",
    "\n",
    "            if text != \"\":\n",
    "                #print(f\"Detected license plate text: {text}\")\n",
    "\n",
    "                # Initialize car entry\n",
    "                if plate_index == 0:\n",
    "                    car_entry = {\n",
    "                        \"car_id\": car_index,\n",
    "                        \"car_box\": box_car, #.tolist(),\n",
    "                        \"plates\": []\n",
    "                    }\n",
    "\n",
    "                # Add plate data to car entry\n",
    "                car_entry[\"plates\"].append({\n",
    "                    \"plate_box\": box_plate, #.tolist(),\n",
    "                    \"text\": text,\n",
    "                    \"text_confidence\": round(confidence, 5)\n",
    "                })\n",
    "\n",
    "                # Add car entry to car data\n",
    "                car_data.append(car_entry)\n",
    "\n",
    "    # Sometimes a car box overlaps more than one car and this results in there being more that one plate in the car box roi\n",
    "    #\n",
    "    # Need to flag if more than one plate is detected and then determine which one is the correct one.\n",
    "    # this will need to be done by creating a list of the cars and the plates detected in each car box.\n",
    "    # we can then compare the plates detected in each car box to the plates detected in other car boxes.\n",
    "    # a car with only one plate detected will likey have the correct plate assigned to it.\n",
    "    # if a car has more than one plate detected then we can compare the plates detected in that car box to the plates detected in other car boxes.\n",
    "    # this can then be used to remove the false positives.\n",
    "    # we will need to set up a suitable data structure to store the car, plate, and text data.\n",
    "    # we will only add cars that have plates with text to the data structure.\n",
    "\n",
    "    # Process car data to remove false positives\n",
    "    print(f\"Starting review of car data/plate. Length of car data: \", len(car_data))\n",
    "    for car in car_data:\n",
    "        print(f\"Reviewing car: {car}\")\n",
    "        #car_box = car[\"car_box\"]\n",
    "        car_plates = car[\"plates\"]\n",
    "        if len(car_plates) > 1:\n",
    "            # Compare plates with other cars\n",
    "            for other_car in car_data:\n",
    "                print(f\"Reviewing other_car: {other_car}\")\n",
    "                if np.array_equal(other_car[\"car_box\"], car[\"car_box\"]): # Skip the same car\n",
    "                    print(f\"Skipping other_car as it's the same as car\")\n",
    "                    continue\n",
    "                #other_car_box = other_car[\"car_box\"]\n",
    "                other_car_plates = other_car[\"plates\"]\n",
    "                for car_plate in car_plates: # Compare each car_plate with each other_car_plate\n",
    "                    car_plate_text = car_plate[\"text\"]\n",
    "                    for other_car_plate in other_car_plates:\n",
    "                        other_car_plate_text = other_car_plate[\"text\"]\n",
    "                        print(f\"Reviewing car_plate: {car_plate}, and other_car_plate: {other_car_plate}\")\n",
    "                        # Check if the plate is a false positive\n",
    "                        if np.array_equal(car_plate_text, other_car_plate_text):\n",
    "                            print(f\"Removing false positive plate: {car_plate}\")\n",
    "                            #if np.any(plate):  # or np.all(plate) depending on your condition ???????\n",
    "                            #if np.all(plate):  # or np.all(plate) depending on your condition ???????\n",
    "                            car_plates.remove(car_plate)\n",
    "                            break\n",
    "\n",
    "    # Process car data to draw bounding boxes and text\n",
    "    print(f\"Starting drawing boxes and text\")\n",
    "    # Draw the frame number\n",
    "    text_0 = \"frame num: \" + str(frame_num)\n",
    "    cv2.putText(image, text_0, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2) # Draws PLATE text above the plate bounding box\n",
    "    for car in car_data:\n",
    "        box_car = car[\"car_box\"]\n",
    "        car_id = car[\"car_id\"]\n",
    "        plates = car[\"plates\"]\n",
    "        c_x1, c_y1, c_x2, c_y2 = box_car.astype(int)\n",
    "        for plate in plates:\n",
    "            box_plate = plate[\"plate_box\"]\n",
    "            text_1 = \"car: \" + str(car_id) +\", plate: \" +plate[\"text\"]\n",
    "            text_2 = \"confidence: \" + str(plate[\"text_confidence\"])\n",
    "            bp_x1, bp_y1, bp_x2, bp_y2 = box_plate.astype(int)\n",
    "            p_x1, p_y1, p_x2, p_y2 = bp_x1 + c_x1, bp_y1 + c_y1, bp_x2 + c_x1, bp_y2 + c_y1\n",
    "\n",
    "            # Extract the region of interest (ROI) for the number plate\n",
    "            cv2.rectangle(image, (c_x1, c_y1), (c_x2, c_y2), (0, 255, 0), 2) # Draws CAR bounding box\n",
    "            cv2.rectangle(image, (p_x1, p_y1), (p_x2, p_y2), (0, 255, 0), 2) # Draws PLATE bounding box inside the car bounding box\n",
    "            cv2.putText(image, text_1, (p_x1, p_y1-35), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2) # Draws PLATE text above the plate bounding box\n",
    "            cv2.putText(image, text_2, (p_x1, p_y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2) # Draws PLATE text above the plate bounding box\n",
    "\n",
    "    # Save the image with boxes\n",
    "    if output_path!=\"\":\n",
    "        cv2.imwrite(output_path, image)\n",
    "        print(f\"Saved processed image to: {output_path}\")\n",
    "\n",
    "    print(f\"Image processing finished\\n\")\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c52457a-9632-41d4-86c2-12125894f42c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Process video frames\n",
    "def process_videos(input_path, output_path, frame_gap=20):\n",
    "    print(f\"Processing videos from: {input_path}, to {output_path}\\n\")\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    input_files = glob.glob(os.path.join(input_path, \"*.mp4\"))\n",
    "\n",
    "    print(f\"video file path list: {input_files}\")\n",
    "\n",
    "    # Process each image file\n",
    "    for input_file_path in input_files:\n",
    "        input_file_name = os.path.basename(input_file_path)\n",
    "        output_file_path = os.path.join(output_path, f\"processed_{input_file_name}\")\n",
    "\n",
    "        print(f\"video file paths: {input_file_path}, {output_file_path}\")\n",
    "\n",
    "        cap = cv2.VideoCapture(input_file_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video file {input_file_path}\")\n",
    "            return\n",
    "        \n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_file_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "        frame_num = 0\n",
    "        next_frame = 0\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_num != next_frame:\n",
    "                frame_num += 1\n",
    "                continue\n",
    "\n",
    "            next_frame = frame_num + frame_gap\n",
    "            print(f\"processing frame: {frame_num}\")\n",
    "            # Process the frame\n",
    "            #output_image_file_path = os.path.join(output_path, f\"processed_{input_file_name}_{str(frame_num)}.jpg\")\n",
    "            processed_frame = process_image(frame, frame_num)\n",
    "\n",
    "            # Check if processed_frame is None\n",
    "            if processed_frame is None:\n",
    "                print(f\"Error processing frame {frame_num}\")\n",
    "                frame_num += 1\n",
    "                continue\n",
    "\n",
    "            #height, width, channels = processed_frame.shape\n",
    "            #size = processed_frame.size\n",
    "            #print(f\"Processed frame shape: Height: {height}, Width: {width}, Channels: {channels}\")\n",
    "            #print(f\"Processed frame size: {size} pixels\")\n",
    "\n",
    "            # Write the processed frame to the output video\n",
    "            out.write(processed_frame)\n",
    "            frame_num += 1\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    print(f\"Processing videos finished\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce4b3c-3639-4416-ac0d-ed610adb9ba9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Process video frames\n",
    "def process_images(input_path, output_path):\n",
    "    print(f\"Processing images from: {input_path}, to {output_path}\\n\")\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    #input_image_files = glob.glob(os.path.join(input_path, \"*.jpg\"))\n",
    "    # Define the list of file extensions\n",
    "    extensions = [\"*.jpg\", \"*.jpeg\", \"*.png\"]\n",
    "\n",
    "    # Collect all files with the specified extensions\n",
    "    input_image_files = []\n",
    "    for ext in extensions:\n",
    "        input_image_files.extend(glob.glob(os.path.join(input_path, ext)))\n",
    "\n",
    "    # Process each image file\n",
    "    for input_image_file in input_image_files:\n",
    "        input_file_name = os.path.basename(input_image_file)\n",
    "        output_file_name = os.path.join(output_path, f\"processed_{input_file_name}\")\n",
    "        print(f\"Processing image: {input_file_name}, to {output_file_name}\")\n",
    "        image = cv2.imread(input_image_file)\n",
    "        process_image(image, output_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb6175-664c-4f0e-ae8c-58eeaf2c7309",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f\"Processing has started\\n\")\n",
    "\n",
    "    input_folder = \"../data\"\n",
    "    output_folder = \"../data/processed\"\n",
    "    process_videos(input_folder, output_folder)\n",
    "\n",
    "    process_images(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77dc06-d4ff-40d1-bad0-407dc4a5d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = [{'plate_box': np.array([     532.59,      258.49,      712.86,       335.7], dtype=np.float32), 'text': 'LDE383', 'text_confidence': 0.99289}, \n",
    "          {'plate_box': np.array([     1490.4,      616.32,      1699.8,      700.75], dtype=np.float32), 'text': 'LDE383', 'text_confidence': 0.98179}, \n",
    "          {'plate_box': np.array([      612.5,      944.33,      729.64,      997.53], dtype=np.float32), 'text': 'NAIRN ST', 'text_confidence': 0.93628}, \n",
    "          {'plate_box': np.array([     1008.8,      732.78,      1130.7,      783.31], dtype=np.float32), 'text': 'NAIRN ST', 'text_confidence': 0.92871}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c17632-9517-4125-9a3d-45e3f851e6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plates.any({'plate_box': np.array([     1008.8,      732.78,      1130.7,      783.31], dtype=np.float32), 'text': 'NAIRN ST', 'text_confidence': 0.92871})\n",
    "\n",
    "for i in range(len(plates)):\n",
    " print(i, plates[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7920aa-bd61-4719-8068-0e6fe1a0483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "\n",
    "import ffmpeg\n",
    "import sys\n",
    "from pprint import pprint # for printing Python dictionaries in a human-readable way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5333a13-4ffa-4fc6-a835-1b06d2e15630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the audio/video file from the command line arguments\n",
    "media_path = \"../data/\"\n",
    "media_file = \"../data/GH010341.MP4\"\n",
    "#media_file = sys.argv[1]\n",
    "\n",
    "#os.chdir(media_path)\n",
    "\n",
    "# uses ffprobe command to extract all possible metadata from the media file\n",
    "pprint(ffmpeg.probe(media_file)[\"streams\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
